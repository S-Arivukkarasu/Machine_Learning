{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450f58df-1ddd-4784-bb59-60db6d87a044",
   "metadata": {},
   "source": [
    "# Practice Fundamentals: Most Basic Form of Training LLMs üí™\n",
    "\n",
    "## Learning Objectives üéØ\n",
    "- Set up the development environment to utilize GPU resources.\n",
    "- Understand and install specific library versions directly from a repository.\n",
    "- Familiarize with YAML configuration for training setups.\n",
    "- Execute a basic training session for a language model using the Axolotl library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c3176a-97bb-4b94-bdac-b3300b94002d",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07e11686-6cac-485e-8e69-46ac54a45006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bde092-5d9b-4b04-a955-5057b0c40e50",
   "metadata": {},
   "source": [
    "## Library Installation üõ†Ô∏è\n",
    "Install the Axolotl library directly from GitHub to ensure compatibility with the course's specified version. This step ensures that the environment matches the course requirements without needing advanced hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25353bb6-9a08-4c90-a0e6-6a8f22a03a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-build-isolation axolotl[flash-attn,deepspeed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c09b65b-ae00-4bef-bc27-5a5f56c69f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "train_config = \"\"\"\n",
    "# Model Parameters\n",
    "# Model_name\n",
    "base_model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
    "# Model-type \n",
    "model_type: LlamaForCausalLM\n",
    "# tokenizer\n",
    "tokenizer_type: LlamaTokenizer\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "datasets:\n",
    "    - path: jaydenccc/AI_Storyteller_Dataset\n",
    "      # formatting this dataset\n",
    "      type:\n",
    "          system_prompt: \"\"\n",
    "          field_system: system\n",
    "          # field instruction is the input for our model \n",
    "          field_instruction: synopsis\n",
    "          # field output is the output column\n",
    "          field_output: short_story\n",
    "          # now we will give the format of the chat template\n",
    "          # some times the column wont have data so specifing the model to follw same structure\n",
    "          format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
    "          no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
    "\n",
    "\n",
    "# saving the final trained model in a directory\n",
    "output_dir: ./models/Tiny_Llama_Storyteller\n",
    "\n",
    "# Model_parameters\n",
    "sequence_length: 1024\n",
    "bf16: auto\n",
    "tf32: false\n",
    "\n",
    "# Training Parameters\n",
    "batch_size: 4\n",
    "micro_batch_size: 2\n",
    "num_epochs: 4\n",
    "# optimizer is set from axolotl\n",
    "optimizer: adamw_bnb_8bit\n",
    "learning_rate: 0.0002\n",
    "\n",
    "logging_steps: 1\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Convert the YAML string to a Python dictionary\n",
    "yaml_dict = yaml.safe_load(train_config)\n",
    "\n",
    "\n",
    "# Write the YAML file\n",
    "with open(\"basic_train.yml\", 'w') as file:\n",
    "    yaml.dump(yaml_dict, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04468e35-95e0-4d17-b1ec-6ebd485215d8",
   "metadata": {},
   "source": [
    "## Training Launch üöÄ\n",
    "Launch the training process with the `accelerate` command. This command is optimized for use even with free-tier resources, ensuring that you can train models effectively without requiring premium hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fb363b-4e90-4249-83f2-a499a45ea4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !accelerate launch -m axolotl.cli.train basic_train.yml\n",
    "# training this in colab "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d9ec4d-90d7-42ab-ae69-0adf2fcdd488",
   "metadata": {},
   "source": [
    "## Importing those model from huggingface \n",
    "If you are training locally give the model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a948659-840b-4c57-b138-a1cab333fe9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|user|>\\nA Man who was a gangster, now living a regular life with his family but his past ememies still want him dead</s>\\n<|assistant|>\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"Arivukkarasu/Tiny_Llama_Storyteller\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
    "\n",
    "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"A Man who was a gangster, now living a regular life with his family but his past ememies still want him dead\"},\n",
    "]\n",
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aeccaf58-10d8-4ca8-9e9b-d58354bdd560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Arivukkarasu/Tiny_Llama_Storyteller\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c1ae9ac5-f5ec-472d-9a12-3cc0ea4c4c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 41])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors='pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1d3b505-7fe8-475d-9051-3aa54ac5307f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "A Man who was a gangster, now living a regular life with his family but his past ememies still want him dead</s>\n",
      "<|assistant|>\n",
      "Emily had always been a silent and reserved child, raised by her mother to be a sharpshooter for the family. But when her mother passed away, her life took a toll. She began to wake up in a trudder, unable to sleep. And his mind would wander during the day. Day by day, she found herself overwhelmed by the sheer scale of what she had uncovered. She had no room for error, and she had to be vigilant at all times.\n",
      "\n",
      "One day, while staking out a local park, Jake saw a suspicious figure lurking in the shadows. She approached cautiously, her hand already on her firearm. As she got closer, she noticed the figure was a young woman, hunching over a piece of paper. The woman was afraid of approaching the cautiously noted man, but she knew she had to do it to stay alive.\n",
      "\n",
      "With her hand on her firearm, Jake took her message directly to the people, holding rallies and community events. Her popularity soared, and her opponents began to panic. They tried to intimidate her, sending her hate mail and even threatening her life.\n",
      "\n",
      "But Jake was not deterred. She was a strong woman who had overcome adversity her whole life, and she knew she had what it took to succeed. The key was sheer determination and a fierce sense of loyalty to her community.\n",
      "\n",
      "And that determination breathed new life into her sights, reminding her that there was always a way out of the crosshairs of the family and friends. And in that moment, Jake realized that her past self was worth everything. He had built a new life for herself, one filled with excitement and challenges. And though she would never forget her family and friends, she knew that she had found the true cost of ambition and greed.\n"
     ]
    }
   ],
   "source": [
    "# outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "# For now we keep this output as simple \n",
    "outputs = pipe(prompt, max_new_tokens=2048)\n",
    "print(outputs[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59e93e-569a-4e67-9bb4-328205c9d3d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
