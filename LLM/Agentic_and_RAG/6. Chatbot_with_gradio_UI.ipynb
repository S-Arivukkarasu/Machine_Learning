{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a13bbc13-0dec-4465-9a8c-bd3cce828b50",
   "metadata": {},
   "source": [
    "# Conversational AI - aka Chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cb5df73-b3c6-4e8f-bdef-4b360a747420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from bs4 import BeautifulSoup\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e835e445-4a18-4f6d-8762-3e52ae226650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing System Messages and ollama details\n",
    "\n",
    "system_message = \"You are a helpful assistant\"\n",
    "OLLAMA_URL = \"http://localhost:11434/api/chat\"\n",
    "MODEL_NAME=\"gemma3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec0b7a5-3e80-4bce-9521-f0bc237ca4f0",
   "metadata": {},
   "source": [
    "``chat(message, history)``\n",
    "\n",
    "Which expects to receive history in a particular format\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7ee695-84cf-4ad2-9db3-f00006c5e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    print(\"history is\\n\", history)\n",
    "    print(\"Message is\\n\", message)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.8,\n",
    "        \"stream\": True  # Important: to get streaming responses\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    response = requests.post(OLLAMA_URL, json=payload, stream=True)\n",
    "    result=\"\"\n",
    "    try:\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    data = json.loads(line.decode('utf-8'))\n",
    "                    delta = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "                    if delta:\n",
    "                        # Optional: remove unwanted <think> tags or others\n",
    "                        clean_delta = re.sub(r\"<think>.*?</think>\", \"\", delta, flags=re.DOTALL)\n",
    "                        result += clean_delta\n",
    "                        yield result\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    finally:\n",
    "        # Ensure generator exits cleanly\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ec745-3bf5-4222-b267-5b324421124b",
   "metadata": {},
   "source": [
    "## Gradio Chat UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d532c56-0313-4f39-94f2-02b30a4730d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexender/Desktop/Projects/My_projects/envs/Torch_env/lib/python3.12/site-packages/gradio/chat_interface.py:328: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history is\n",
      " []\n",
      "Message is\n",
      " hello\n",
      "history is\n",
      " [{'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello there! How can I help you today? ðŸ˜Š \\n\\nDo you have a question, need some information, want to brainstorm, or just want to chat? Let me know!', 'options': None}]\n",
      "Message is\n",
      " what is today's date\n",
      "history is\n",
      " [{'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello there! How can I help you today? ðŸ˜Š \\n\\nDo you have a question, need some information, want to brainstorm, or just want to chat? Let me know!', 'options': None}, {'role': 'user', 'metadata': None, 'content': \"what is today's date\", 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Today is Wednesday, November 8th, 2023. \\n\\nHowâ€™s your day going so far?', 'options': None}]\n",
      "Message is\n",
      " i am arivukkarasu\n",
      "history is\n",
      " [{'role': 'user', 'metadata': None, 'content': 'hello', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Hello there! How can I help you today? ðŸ˜Š \\n\\nDo you have a question, need some information, want to brainstorm, or just want to chat? Let me know!', 'options': None}, {'role': 'user', 'metadata': None, 'content': \"what is today's date\", 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Today is Wednesday, November 8th, 2023. \\n\\nHowâ€™s your day going so far?', 'options': None}, {'role': 'user', 'metadata': None, 'content': 'i am arivukkarasu', 'options': None}, {'role': 'assistant', 'metadata': None, 'content': 'Arivukkarasu! Thatâ€™s a beautiful name. Itâ€™s lovely to meet you. ðŸ˜Š \\n\\nIs there anything youâ€™d like to tell me about yourself, or were you just saying hello?', 'options': None}]\n",
      "Message is\n",
      " what is my name \n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, chatbot=gr.Chatbot(type=\"messages\")).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77681c7-820f-4954-9599-039c35f5271f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a44ebb0-ebd6-421a-bc8c-704c87b149a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant in a clothes store. You should try to gently encourage \\\n",
    "the customer to try items that are on sale. Hats are 60% off, and most other items are 50% off. \\\n",
    "For example, if the customer says 'I'm looking to buy a hat', \\\n",
    "you could reply something like, 'Wonderful - we have lots of hats - including several that are part of our sales event.'\\\n",
    "Encourage the customer to buy hats if they are unsure what to get.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edc906e5-7716-43c5-8ba0-22aa021684ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.8,\n",
    "        \"stream\": True  # Important: to get streaming responses\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    response = requests.post(OLLAMA_URL, json=payload, stream=True)\n",
    "    result=\"\"\n",
    "    try:\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    data = json.loads(line.decode('utf-8'))\n",
    "                    delta = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "                    if delta:\n",
    "                        # Optional: remove unwanted <think> tags or others\n",
    "                        clean_delta = re.sub(r\"<think>.*?</think>\", \"\", delta, flags=re.DOTALL)\n",
    "                        result += clean_delta\n",
    "                        yield result\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    finally:\n",
    "        # Ensure generator exits cleanly\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3606b95a-19d7-4c9c-b4fc-586dcfa00a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexender/Desktop/Projects/My_projects/envs/Torch_env/lib/python3.12/site-packages/gradio/chat_interface.py:328: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, chatbot=gr.Chatbot(type=\"messages\")).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de272390-2259-4b48-b52f-106474bfb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "441c8ffb-4311-4cbc-9dd1-aa85ff23aaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexender/Desktop/Projects/My_projects/envs/Torch_env/lib/python3.12/site-packages/gradio/chat_interface.py:328: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, chatbot=gr.Chatbot(type=\"messages\")).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51ad8104-2961-4dc7-840b-429a04309def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    final_system_message = system_message\n",
    "    if \"belt\" in message:\n",
    "        final_system_message += \" The store does not sell belts; if you are asked for belts, be sure to point out other items on sale.\"\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": final_system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": 0.8,\n",
    "        \"stream\": True  # Important: to get streaming responses\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    response = requests.post(OLLAMA_URL, json=payload, stream=True)\n",
    "    result=\"\"\n",
    "    try:\n",
    "        for line in response.iter_lines():\n",
    "            if line:\n",
    "                try:\n",
    "                    data = json.loads(line.decode('utf-8'))\n",
    "                    delta = data.get(\"message\", {}).get(\"content\", \"\")\n",
    "                    if delta:\n",
    "                        # Optional: remove unwanted <think> tags or others\n",
    "                        clean_delta = re.sub(r\"<think>.*?</think>\", \"\", delta, flags=re.DOTALL)\n",
    "                        result += clean_delta\n",
    "                        yield result\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    finally:\n",
    "        # Ensure generator exits cleanly\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e027f2f9-c3ee-4bd4-9105-ab12a48e7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexender/Desktop/Projects/My_projects/envs/Torch_env/lib/python3.12/site-packages/gradio/chat_interface.py:328: UserWarning: The gr.ChatInterface was not provided with a type, so the type of the gr.Chatbot, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, chatbot=gr.Chatbot(type=\"messages\")).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482b83a-1a9b-486d-bd3d-3f9cd56236b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
