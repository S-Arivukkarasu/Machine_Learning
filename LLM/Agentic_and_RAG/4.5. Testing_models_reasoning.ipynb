{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "336713a4-10ab-4f0f-85f3-0a2b6864c54d",
   "metadata": {},
   "source": [
    "# Asking LLMs to solve a problem\n",
    "\n",
    "Asking LLMs to solve some problems this will check their reasoning ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8504f61-ed85-4c00-8485-304de2e18223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Libraries\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "from typing import List\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca9cb1f-734a-42d7-8cd0-2a1b8840ff73",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_URL = \"http://localhost:11434/api/chat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "767b3bd0-d08c-435d-99d8-3d3d1ba8137d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_test(model_name:str, prompts):\n",
    "    payload = {\n",
    "        \"model\": model_name,\n",
    "        \"messages\": prompts,\n",
    "        \"think\": True,   # It will enable the thinking/reasoning capacity of the model\n",
    "        \"stream\": False  # Important: to get streaming responses\n",
    "    }\n",
    "    start_time = time.time()\n",
    "    response = requests.post(OLLAMA_URL, json=payload, stream=False)\n",
    "    reply = response.json()[\"message\"][\"content\"]\n",
    "    reply = re.sub(r\"<think>.*?</think>\", \"\", reply, flags=re.DOTALL).strip()\n",
    "    print(f\"Model Name: {model_name}\\n\")\n",
    "    display(Markdown(reply))\n",
    "    print(\"Total Time Taken: \", time.time()-start_time, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302d2c49-77dc-4865-b8de-f3e5cacd6a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only some models from ollama supports the reasoning we need to pick those models to test this problems\n",
    "\n",
    "model_list = [\"qwen3\", \"deepseek-r1:14b\", \"gpt-oss\"] # get this from ollama list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3dce5e-a1f9-4bb9-ad67-0d4069ccc6c9",
   "metadata": {},
   "source": [
    "### Training vs Inference time scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7963dce3-6bd5-4404-aa10-8b713a989b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_puzzle = [\n",
    "    {\"role\": \"user\", \"content\": \n",
    "        \"You toss 2 coins. One of them is heads. What's the probability the other is tails? Answer with the probability only.\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "168cddb6-1637-4871-9b2b-f67a6367f0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: qwen3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To determine the probability that the *other* coin is tails, given that **one of the two coins is heads**, we must carefully analyze the possible outcomes and the information provided.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 1: Understand the Sample Space\n",
       "\n",
       "When two fair coins are tossed, the possible outcomes are:\n",
       "\n",
       "- **HH** (both heads)\n",
       "- **HT** (first is heads, second is tails)\n",
       "- **TH** (first is tails, second is heads)\n",
       "- **TT** (both tails)\n",
       "\n",
       "Each outcome is equally likely, with a probability of $ \\frac{1}{4} $.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 2: Interpret the Given Information\n",
       "\n",
       "The problem states: *“One of them is heads.”* This is interpreted as **at least one coin is heads**, not that **exactly one** is heads or that **a specific coin** is heads. Therefore, the outcome **TT** is eliminated, and we're left with:\n",
       "\n",
       "- **HH**\n",
       "- **HT**\n",
       "- **TH**\n",
       "\n",
       "These are the only outcomes that satisfy the condition that **at least one coin is heads**.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 3: Determine the Favorable Outcomes\n",
       "\n",
       "We are to find the probability that the **other** coin is tails. That is, we want the probability that **exactly one** of the coins is heads (since if one is heads, the other must be tails to satisfy the condition).\n",
       "\n",
       "From the reduced sample space:\n",
       "\n",
       "- **HT** → one head, one tail\n",
       "- **TH** → one head, one tail\n",
       "- **HH** → two heads\n",
       "\n",
       "So, **two out of the three** outcomes (HT and TH) result in the other coin being tails.\n",
       "\n",
       "---\n",
       "\n",
       "### Step 4: Compute the Probability\n",
       "\n",
       "The probability that the other coin is tails, given that at least one is heads, is:\n",
       "\n",
       "$$\n",
       "\\frac{\\text{Number of favorable outcomes}}{\\text{Total number of possible outcomes}} = \\frac{2}{3}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### Final Answer\n",
       "\n",
       "$$\n",
       "\\boxed{\\dfrac{2}{3}}\n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  604.8166105747223 \n",
      "\n",
      "\n",
      "Model Name: deepseek-r1:14b\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To determine the probability that one coin is Heads and the other is Tails when at least one coin shows Heads, follow these steps:\n",
       "\n",
       "1. **Identify All Possible Outcomes:**\n",
       "   \n",
       "   When tossing two coins, there are four possible outcomes:\n",
       "   - Heads & Heads (HH)\n",
       "   - Heads & Tails (HT)\n",
       "   - Tails & Heads (TH)\n",
       "   - Tails & Tails (TT)\n",
       "\n",
       "2. **Exclude the Outcome Where Both Are Tails:**\n",
       "   \n",
       "   Since one of the coins is known to be Heads, we can eliminate the outcome where both coins are Tails (TT). This leaves us with three possible outcomes:\n",
       "   - HH\n",
       "   - HT\n",
       "   - TH\n",
       "\n",
       "3. **Determine Favorable Outcomes:**\n",
       "   \n",
       "   We're interested in cases where one coin is Heads and the other is Tails. These are:\n",
       "   - HT\n",
       "   - TH\n",
       "\n",
       "4. **Calculate the Probability:**\n",
       "   \n",
       "   The number of favorable outcomes is 2, and the total possible outcomes after eliminating TT are 3.\n",
       "\n",
       "   \\[\n",
       "   \\text{Probability} = \\frac{\\text{Number of Favorable Outcomes}}{\\text{Total Possible Outcomes}} = \\frac{2}{3}\n",
       "   \\]\n",
       "\n",
       "**Final Answer:**\n",
       "\n",
       "\\boxed{\\dfrac{2}{3}}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  133.46091604232788 \n",
      "\n",
      "\n",
      "Model Name: gpt-oss\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "2/3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  63.571455240249634 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    model_test(model, easy_puzzle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffcaf7d-18ab-4d31-9946-067ef438506b",
   "metadata": {},
   "source": [
    "### Testing out the models but with little bit difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "153fdc57-5114-4e1c-ab68-f6b25dcc7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard = \"\"\"\n",
    "On a bookshelf, two volumes of Pushkin stand side by side: the first and the second.\n",
    "The pages of each volume together have a thickness of 2 cm, and each cover is 2 mm thick.\n",
    "A worm gnawed (perpendicular to the pages) from the first page of the first volume to the last page of the second volume.\n",
    "What distance did it gnaw through?\n",
    "\"\"\"\n",
    "hard_puzzle = [\n",
    "    {\"role\": \"user\", \"content\": hard}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec2901bc-2ba8-4cf1-8efe-2f8ffb0c1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: qwen3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To determine how far the worm gnawed, we need to consider the structure of the two volumes and the path it took.\n",
       "\n",
       "---\n",
       "\n",
       "### **Understanding the Structure of Each Volume**\n",
       "\n",
       "Each volume is composed of:\n",
       "\n",
       "- **Pages**: 2 cm thick\n",
       "- **Front Cover**: 2 mm thick\n",
       "- **Back Cover**: 2 mm thick\n",
       "\n",
       "Thus, the total thickness of each volume is:\n",
       "$$\n",
       "2\\ \\text{cm} + 2\\ \\text{mm} + 2\\ \\text{mm} = 24\\ \\text{mm}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### **Path of the Worm**\n",
       "\n",
       "The worm starts at the **first page of the first volume**, which is **after the front cover** of that volume.\n",
       "\n",
       "It ends at the **last page of the second volume**, which is **before the back cover** of that volume.\n",
       "\n",
       "So, the worm's path includes:\n",
       "\n",
       "1. **All the pages of the first volume**: 2 cm (20 mm)\n",
       "2. **The back cover of the first volume**: 2 mm\n",
       "3. **The front cover of the second volume**: 2 mm\n",
       "4. **All the pages of the second volume**: 2 cm (20 mm)\n",
       "\n",
       "---\n",
       "\n",
       "### **Calculating the Total Distance**\n",
       "\n",
       "Adding up these distances:\n",
       "$$\n",
       "20\\ \\text{mm} + 2\\ \\text{mm} + 2\\ \\text{mm} + 20\\ \\text{mm} = 44\\ \\text{mm}\n",
       "$$\n",
       "\n",
       "Converting to centimeters:\n",
       "$$\n",
       "44\\ \\text{mm} = 4.4\\ \\text{cm}\n",
       "$$\n",
       "\n",
       "---\n",
       "\n",
       "### **Conclusion**\n",
       "\n",
       "The worm gnawed through a total of:\n",
       "\n",
       "$$\n",
       "\\boxed{4.4}\n",
       "$$\n",
       "\n",
       "**centimeters.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  774.0899741649628 \n",
      "\n",
      "\n",
      "Model Name: deepseek-r1:14b\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To determine the distance from the first page of the first book to the last page of the second book on a shelf where they are placed side by side, we need to consider the structure of each book. Each book has a front cover of 2 mm, a back cover of 2 mm, and pages that are 20 mm thick.\n",
       "\n",
       "1. **Breakdown of each book:**\n",
       "   - Front cover: 2 mm\n",
       "   - Pages: 20 mm\n",
       "   - Back cover: 2 mm\n",
       "\n",
       "2. **Positioning on the shelf:**\n",
       "   - The first book occupies positions 0 to 24 mm.\n",
       "     - Front cover: 0-2 mm\n",
       "     - Pages: 2-22 mm\n",
       "     - Back cover: 22-24 mm\n",
       "   - The second book starts at position 24 mm and occupies positions 24 to 48 mm.\n",
       "     - Front cover: 24-26 mm\n",
       "     - Pages: 26-46 mm\n",
       "     - Back cover: 46-48 mm\n",
       "\n",
       "3. **Distance calculation:**\n",
       "   - The first page of the first book is at position 2 mm.\n",
       "   - The last page of the second book is at position 46 mm.\n",
       "   - The distance between these two points is \\(46 - 2 = 44\\) mm.\n",
       "\n",
       "Thus, the total distance from the first page of the first book to the last page of the second book is \\(\\boxed{44}\\) mm."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  1973.7783906459808 \n",
      "\n",
      "\n",
      "Model Name: gpt-oss\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The worm travels only through the “width” (thickness) of the books.\n",
       "\n",
       "- Volume 1 pages  = 2 cm = 20 mm  \n",
       "- Back cover of Volume 1 = 2 mm  \n",
       "- Front cover of Volume 2 = 2 mm  \n",
       "- Volume 2 pages  = 2 cm = 20 mm  \n",
       "\n",
       "Adding those parts:\n",
       "\n",
       "\\(20\\text{ mm} + 2\\text{ mm} + 2\\text{ mm} + 20\\text{ mm} = 44\\text{ mm}\\).\n",
       "\n",
       "So the worm gnawed **44 mm (4.4 cm)** in total."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  255.9420030117035 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    model_test(model, hard_puzzle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151d056-69d5-4b66-a09a-10600edd1051",
   "metadata": {},
   "source": [
    "### A spicy challenge to test the competitive spirit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d39b600-62ff-4099-8575-f96f8b7480c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dilemma_prompt = \"\"\"\n",
    "You and a partner are contestants on a game show. You're each taken to separate rooms and given a choice:\n",
    "Cooperate: Choose \"Share\" — if both of you choose this, you each win $1,000.\n",
    "Defect: Choose \"Steal\" — if one steals and the other shares, the stealer gets $2,000 and the sharer gets nothing.\n",
    "If both steal, you both get nothing.\n",
    "Do you choose to Steal or Share? Pick one.\n",
    "\"\"\"\n",
    "\n",
    "dilemma = [\n",
    "    {\"role\": \"user\", \"content\": dilemma_prompt},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9761ee77-1eb6-4557-9c2a-80a08fee9467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: qwen3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In this scenario, the decision hinges on the classic **Prisoner's Dilemma** structure, where individual rationality leads to a suboptimal outcome for both players. Here's the breakdown:\n",
       "\n",
       "1. **If you choose to Steal (Defect):**  \n",
       "   - If your partner also Steals, you both get **$0**.  \n",
       "   - If your partner Shares, you get **$2,000**.  \n",
       "\n",
       "2. **If you choose to Share (Cooperate):**  \n",
       "   - If your partner also Shares, you both get **$1,000**.  \n",
       "   - If your partner Steals, you get **$0**.  \n",
       "\n",
       "### Key Considerations:\n",
       "- **Dominant Strategy:** In a one-time, anonymous interaction, the **rational choice** for an individual is to **Steal** (Defect). This is because:  \n",
       "  - If you assume your partner will **Share**, you gain **$2,000** by stealing.  \n",
       "  - If you assume your partner will **Steal**, you avoid losing **$1,000** by also stealing (both get $0).  \n",
       "  - Stealing maximizes your potential payoff regardless of the partner’s choice.  \n",
       "\n",
       "- **Risk of Trust:** Choosing to Share risks losing everything if your partner defects. Without communication or trust, the safer (self-interested) choice is to Steal.  \n",
       "\n",
       "- **Nash Equilibrium:** The only stable outcome in this scenario is **both Stealing**, leading to **$0** for both. While this is suboptimal for the group, it is the outcome when both act rationally.  \n",
       "\n",
       "### Final Answer:  \n",
       "**Steal**.  \n",
       "While mutual cooperation would yield $1,000 each, the rational choice in a one-time, anonymous interaction is to **Steal** to avoid the risk of losing out entirely. The dominant strategy ensures you maximize your own gain, even if it results in a worse collective outcome.  \n",
       "\n",
       "**Answer:** Steal."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  159.45117616653442 \n",
      "\n",
      "\n",
      "Model Name: deepseek-r1:14b\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In this game show scenario, which is akin to the Prisoner's Dilemma, each contestant must decide independently whether to Cooperate (Share) or Defect (Steal). The possible outcomes are as follows:\n",
       "\n",
       "1. **Both Share**: Each contestant receives $1,000.\n",
       "2. **One Shares, the Other Steals**: The stealer gets $2,000 while the sharer gets nothing.\n",
       "3. **Both Steal**: Both contestants receive nothing.\n",
       "\n",
       "Analyzing from a game theory perspective, particularly considering the Nash equilibrium, each individual's rational choice is to Defect (Steal). This is because defecting maximizes one's own potential gain regardless of the other's decision. If both decide to Steal, they end up with nothing, which is the Nash equilibrium as neither can improve their outcome by changing their strategy unilaterally.\n",
       "\n",
       "However, if there were trust or communication, choosing Share could lead to a better mutual outcome. Without such assurances, the rational choice aligns with defecting.\n",
       "\n",
       "**Decision**: Choose **Steal**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  308.85629439353943 \n",
      "\n",
      "\n",
      "Model Name: gpt-oss\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Steal**  \n",
       "\n",
       "In this one‑shot game the payoff matrix is:\n",
       "\n",
       "|                 | Partner: Share | Partner: Steal |\n",
       "|-----------------|----------------|----------------|\n",
       "| **You: Share** | 1,000 / 1,000  | 0 / 2,000      |\n",
       "| **You: Steal** | 2,000 / 0      | 0 / 0          |\n",
       "\n",
       "No matter what your partner does, stealing gives you a higher or equal payoff:\n",
       "\n",
       "- If the partner shares, you get $2,000 instead of $1,000.\n",
       "- If the partner steals, you get $0 regardless of your choice, so stealing is no worse.\n",
       "\n",
       "Because “Steal” dominates “Share,” the rational, self‑interested choice in a single, non‑repeated round is **Steal**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time Taken:  170.99034667015076 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    model_test(model, dilemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93c75f-f2df-4276-a27b-e6a837db2be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
