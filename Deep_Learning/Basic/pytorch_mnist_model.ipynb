{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b971e9e-dbb7-4b78-8787-8499fc5e2609",
   "metadata": {},
   "source": [
    "# Deep Neural Network for MNIST Classification\n",
    "\n",
    "We'll apply all the knowledge from the lectures in this section to write a deep neural network. The problem we've chosen is referred to as the \"Hello World\" of deep learning because for most students it is the first deep learning algorithm they see.\n",
    "\n",
    "The dataset is called MNIST and refers to handwritten digit recognition. You can find more about it on Yann LeCun's website (Director of AI Research, Facebook). He is one of the pioneers of what we've been talking about and of more complex approaches that are widely used today, such as covolutional neural networks (CNNs). \n",
    "\n",
    "The dataset provides 70,000 images (28x28 pixels) of handwritten digits (1 digit per image). \n",
    "\n",
    "The goal is to write an algorithm that detects which digit is written. Since there are only 10 digits (0, 1, 2, 3, 4, 5, 6, 7, 8, 9), this is a classification problem with 10 classes. \n",
    "\n",
    "Our goal would be to build a neural network with 2 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447e9f15-da28-408f-9363-03a34f9b9cbd",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11bb8c23-7d9b-40a3-a908-ec56616bbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2ab97-93a5-4714-93a6-df8668359c75",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ebef04-17fc-4b95-902d-4c72b8a04b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.91M/9.91M [00:35<00:00, 277kB/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 46.9kB/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.65M/1.65M [00:05<00:00, 287kB/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()  # Converts to float tensor and scales [0,255] → [0,1]\n",
    "])\n",
    "\n",
    "# Images become shape (1, 28, 28) (channels-first, PyTorch style)\n",
    "\n",
    "mnist_train = datasets.MNIST(\n",
    "    root='../../Data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "mnist_test = datasets.MNIST(\n",
    "    root='../../Data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393fcc5b-d8e7-45d6-95cc-5b8c58432fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset MNIST\n",
       "     Number of datapoints: 60000\n",
       "     Root location: ../../Data\n",
       "     Split: Train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset MNIST\n",
       "     Number of datapoints: 10000\n",
       "     Root location: ../../Data\n",
       "     Split: Test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train, mnist_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b902e8a0-2b45-4398-9614-74ef881c7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need validation samples so we are spliting training data using the info we have from the dataset\n",
    "\n",
    "# Same 90% training, 10% validation\n",
    "\n",
    "# random_split handles shuffling internally\n",
    "\n",
    "num_train = len(mnist_train)\n",
    "num_val = int(0.1 * num_train)\n",
    "num_train = num_train - num_val\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    mnist_train, [num_train, num_val]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40c8d07d-c0f4-4bd3-9703-e905a6aa47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling and Batching the data\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=num_val, shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    mnist_test, batch_size=len(mnist_test), shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524c5efb-0549-4a68-b823-849905357eb9",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "#### Outline of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dce4e8ce-7f5d-4f14-892b-2084767dfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28 * 28, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 200)\n",
    "        self.out = nn.Linear(200, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.out(x)  # No softmax here!\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e881a1-76be-4da8-acf7-9ba8f154be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model into GPU if its available\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = MNISTModel().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841daef-9c28-42a8-9973-8d6d27e6e9b3",
   "metadata": {},
   "source": [
    "#### Choosing Optimizer and Loss Function\n",
    "\n",
    "This is a classification problem so we are choosing loss function as 'CrossEntropyLoss' as its best for classification \n",
    "\n",
    "`CrossEntropyLoss = Softmax + NLLLoss`\n",
    "\n",
    "For Optimizer we are choosing the best ADAM optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bfd5b63-2c36-47e4-8c66-36642a29c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5032e130-b09e-4d7d-92e7-66ffac8d3361",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Training the model with the data with early stop using our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5de62306-8d9a-44dd-ad5a-7279c7b76184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 7.7496, Val Loss = 0.1130\n",
      "Epoch 2: Train Loss = 3.5243, Val Loss = 0.1202\n",
      "Epoch 3: Train Loss = 7.1631, Val Loss = 0.1118\n",
      "Epoch 4: Train Loss = 6.1999, Val Loss = 0.1103\n",
      "Epoch 5: Train Loss = 3.6760, Val Loss = 0.1136\n",
      "Epoch 6: Train Loss = 5.8490, Val Loss = 0.1145\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "patience = 2\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # ---- Training ----\n",
    "    model.train() # training mode\n",
    "    train_loss = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # clear old gradients\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward() # backprop\n",
    "        optimizer.step() # update weights\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval() # inference mode\n",
    "    with torch.no_grad(): \n",
    "        val_images, val_labels = next(iter(val_loader))\n",
    "        val_images, val_labels = val_images.to(device), val_labels.to(device)\n",
    "\n",
    "        val_outputs = model(val_images)\n",
    "        val_loss = criterion(val_outputs, val_labels)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: \"\n",
    "          f\"Train Loss = {train_loss:.4f}, \"\n",
    "          f\"Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # ---- Early Stopping ----\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154783f1-f494-4a21-948a-80bd9a446339",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "267bb341-e44a-49d1-952f-c843e031ace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.11, Test Accuracy: 97.94%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_images, test_labels = next(iter(test_loader))\n",
    "    test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "\n",
    "    outputs = model(test_images)\n",
    "    test_loss = criterion(outputs, test_labels)\n",
    "\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    accuracy = (predicted == test_labels).float().mean()\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.2f}, Test Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f40ca26-0832-437b-bdf1-6776afcecc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTModel(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (fc2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (fc3): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (out): Linear(in_features=200, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5bf93-ba59-419a-b2f3-5553863aba7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
